{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "For the machine learning portion, you will split the data into a training set and a test set. Then, you will create a machine learning pipeline that uses NLTK, as well as scikit-learn's Pipeline and GridSearchCV to output a final model that uses the message column to predict classifications for 36 categories (multi-output classification). Finally, you will export your model to a pickle file. After completing the notebook, you'll need to include your final machine learning code in train_classifier.py.\n",
    "\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# connect to the database\n",
    "conn = sqlite3.connect('../data/DisasterResponse.db')\n",
    "\n",
    "# run a query\n",
    "df = pd.read_sql('SELECT * FROM disaster_response_messages', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that could pass over Haiti</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. Il pourrait traverser Haiti demain. Des averses de pluie isolee sont encore prevues sur notre region ce soi</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                             message   \n",
       "0   2  Weather update - a cold front from Cuba that could pass over Haiti  \\\n",
       "\n",
       "                                                                                                                                                    original   \n",
       "0  Un front froid se retrouve sur Cuba ce matin. Il pourrait traverser Haiti demain. Des averses de pluie isolee sont encore prevues sur notre region ce soi  \\\n",
       "\n",
       "    genre  related  request  offer  aid_related  medical_help   \n",
       "0  direct        1        0      0            0             0  \\\n",
       "\n",
       "   medical_products  ...  aid_centers  other_infrastructure  weather_related   \n",
       "0                 0  ...            0                     0                0  \\\n",
       "\n",
       "   floods  storm  fire  earthquake  cold  other_weather  direct_report  \n",
       "0       0      0     0           0     0              0              0  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "#     df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "#     df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "#     X = df.text.values\n",
    "#     y = df.category.values\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[df.columns[4:]].values\n",
    "X = df['message'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/henriettewevell/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/henriettewevell/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/henriettewevell/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(['punkt', 'wordnet','stopwords'])\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# # download necessary NLTK data\n",
    "# import nltk\n",
    "# nltk.download(['punkt', 'wordnet'])\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all_urls(text: str) -> str:\n",
    "        url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "        detected_urls = re.findall(url_regex, text)\n",
    "        for url in detected_urls:\n",
    "             text = text.replace(url, \"urlplaceholder\")\n",
    "        return text\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    test = text.strip() # remove whitespaces\n",
    "    return test\n",
    "\n",
    "def tokenize(text : str) -> list:\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(text : list) -> list:\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    words = [w for w in text if w not in stop_words]\n",
    "    return words\n",
    "\n",
    "def lemmatize(text: list) -> list:\n",
    "    lemmatized_all = []\n",
    "    for word in text:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmatized_all.append(lemmatized)\n",
    "    return lemmatized_all\n",
    "\n",
    "\n",
    "def clean_and_tokenize(text: str) -> list:\n",
    "    text = replace_all_urls(text)\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize(tokens)\n",
    "    return tokens\n",
    "\n",
    "# def tokenize(text):\n",
    "#     detected_urls = re.findall(url_regex, text)\n",
    "#     for url in detected_urls:\n",
    "#         text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "#     tokens = word_tokenize(text)\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#     clean_tokens = []\n",
    "#     for tok in tokens:\n",
    "#         clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "#         clean_tokens.append(clean_tok)\n",
    "\n",
    "#     return clean_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['want',\n",
       " 'find',\n",
       " 'job',\n",
       " 'ngo',\n",
       " 'government',\n",
       " 'upload',\n",
       " 'resume',\n",
       " 'urlplaceholder']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_tokenize(\"If you want to find a Job at an NGO or the Government, upload your resume at http://www.jobpaw.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "# urls_df = df[df['message'].str.contains(url_regex)]['message'].head(1)\n",
    "# urls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilter the df messages column for when url is present\n",
    "# urls_df = df[df['message'].str.contains(url_regex)]['message'].head(5)\n",
    "# urls_df\n",
    "# number_regex = r'\\d+,\\d+'\n",
    "# # or number.number\n",
    "# number_regex2 = r'\\d+\\.\\d+'\n",
    "# # or number\n",
    "# number_regex3 = r'\\d+'\n",
    "\n",
    "# df[df['message'].str.contains(number_regex2)]['message'].sample(n=15)\n",
    "\n",
    "# filter the df messages column for number_regex or number_regex2 or number_regex3 is present\n",
    "# df[df['message'].str.contains(number_regex) | df['message'].str.contains(number_regex2) | df['message'].str.contains(number_regex3)]['message'].sample(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize(df.iloc[10]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_and_letters_regex = r'\\d+[a-zA-Z]+'\n",
    "# letters_and_number_regex = r'[a-zA-Z]+\\d+'\n",
    "# combined_regex = r'(\\d+[a-zA-Z]+)|([a-zA-Z]+\\d+)'\n",
    "# # df[df['message'].str.contains(number_and_letters_regex)]['message'].sample(n=15)\n",
    "\n",
    "# # get number_and_letters_regex from each message\n",
    "# df[df['message'].str.contains(letters_and_number_regex)]['message'].str.findall(letters_and_number_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['message'].str.contains(number_and_letters_regex)]['message'].str.findall(number_and_letters_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['message'].str.contains(combined_regex)]['message'].str.findall(combined_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df messages for when it contains any numbers\n",
    "# df[df['message'].str.contains('\\d')]['message'].sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "# lower case\n",
    "# lemmatize?\n",
    "# remove urls\n",
    "# remove punctuation\n",
    "# remove numbers?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train pipeline\n",
    "clf_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # load data and perform train text split\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # instantiate transformers and classifiers\n",
    "    vect = CountVectorizer(tokenizer=tokenize)\n",
    "    tfidf = TfidfTransformer()\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    # fit and transform the training data\n",
    "    X_train_counts = vect.fit_transform(X_train)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "\n",
    "    # train classifier\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # transform (no fitting) the test data\n",
    "    X_test_counts = vect.transform(X_test)\n",
    "    X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "    # predict on test data\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    # display results\n",
    "    display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "# display_results(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_columns = df[df.columns[4:]].columns\n",
    "y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.26      0.39      1266\n",
      "           1       0.80      0.97      0.87      3938\n",
      "           2       0.75      0.07      0.14        40\n",
      "\n",
      "    accuracy                           0.79      5244\n",
      "   macro avg       0.76      0.44      0.47      5244\n",
      "weighted avg       0.78      0.79      0.75      5244\n",
      "\n",
      "Category: request\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      4349\n",
      "           1       0.89      0.41      0.56       895\n",
      "\n",
      "    accuracy                           0.89      5244\n",
      "   macro avg       0.89      0.70      0.75      5244\n",
      "weighted avg       0.89      0.89      0.87      5244\n",
      "\n",
      "Category: offer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5218\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "Category: aid_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      3113\n",
      "           1       0.79      0.60      0.68      2131\n",
      "\n",
      "    accuracy                           0.77      5244\n",
      "   macro avg       0.78      0.74      0.75      5244\n",
      "weighted avg       0.77      0.77      0.76      5244\n",
      "\n",
      "Category: medical_help\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4822\n",
      "           1       0.69      0.06      0.11       422\n",
      "\n",
      "    accuracy                           0.92      5244\n",
      "   macro avg       0.80      0.53      0.53      5244\n",
      "weighted avg       0.90      0.92      0.89      5244\n",
      "\n",
      "Category: medical_products\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4974\n",
      "           1       0.75      0.06      0.10       270\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.85      0.53      0.54      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "Category: search_and_rescue\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5117\n",
      "           1       0.88      0.06      0.10       127\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.93      0.53      0.55      5244\n",
      "weighted avg       0.97      0.98      0.97      5244\n",
      "\n",
      "Category: security\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5156\n",
      "           1       0.25      0.01      0.02        88\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.62      0.51      0.51      5244\n",
      "weighted avg       0.97      0.98      0.98      5244\n",
      "\n",
      "Category: military\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5089\n",
      "           1       0.50      0.05      0.08       155\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.74      0.52      0.53      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "Category: child_alone\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5244\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       1.00      1.00      1.00      5244\n",
      "weighted avg       1.00      1.00      1.00      5244\n",
      "\n",
      "Category: water\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4905\n",
      "           1       0.91      0.20      0.33       339\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.93      0.60      0.65      5244\n",
      "weighted avg       0.95      0.95      0.93      5244\n",
      "\n",
      "Category: food\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      4649\n",
      "           1       0.90      0.41      0.56       595\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.91      0.70      0.76      5244\n",
      "weighted avg       0.93      0.93      0.92      5244\n",
      "\n",
      "Category: shelter\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4774\n",
      "           1       0.88      0.26      0.40       470\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.90      0.63      0.68      5244\n",
      "weighted avg       0.93      0.93      0.91      5244\n",
      "\n",
      "Category: clothing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5171\n",
      "           1       1.00      0.05      0.10        73\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.99      0.53      0.55      5244\n",
      "weighted avg       0.99      0.99      0.98      5244\n",
      "\n",
      "Category: money\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5140\n",
      "           1       0.75      0.06      0.11       104\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.87      0.53      0.55      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "Category: missing_people\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5184\n",
      "           1       1.00      0.02      0.03        60\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.99      0.51      0.51      5244\n",
      "weighted avg       0.99      0.99      0.98      5244\n",
      "\n",
      "Category: refugees\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5073\n",
      "           1       0.60      0.02      0.03       171\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.78      0.51      0.51      5244\n",
      "weighted avg       0.96      0.97      0.95      5244\n",
      "\n",
      "Category: death\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5007\n",
      "           1       0.79      0.11      0.19       237\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.87      0.55      0.59      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "Category: other_aid\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4549\n",
      "           1       0.79      0.02      0.03       695\n",
      "\n",
      "    accuracy                           0.87      5244\n",
      "   macro avg       0.83      0.51      0.48      5244\n",
      "weighted avg       0.86      0.87      0.81      5244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: infrastructure_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4916\n",
      "           1       0.00      0.00      0.00       328\n",
      "\n",
      "    accuracy                           0.94      5244\n",
      "   macro avg       0.47      0.50      0.48      5244\n",
      "weighted avg       0.88      0.94      0.91      5244\n",
      "\n",
      "Category: transport\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5004\n",
      "           1       0.77      0.08      0.15       240\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.86      0.54      0.56      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "Category: buildings\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4977\n",
      "           1       0.86      0.07      0.12       267\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.90      0.53      0.55      5244\n",
      "weighted avg       0.95      0.95      0.93      5244\n",
      "\n",
      "Category: electricity\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5122\n",
      "           1       1.00      0.02      0.05       122\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.99      0.51      0.52      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "Category: tools\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5212\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "Category: hospitals\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5198\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.99      5244\n",
      "\n",
      "Category: shops\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5222\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "Category: aid_centers\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5177\n",
      "           1       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.97      0.99      0.98      5244\n",
      "\n",
      "Category: other_infrastructure\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5021\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.48      0.50      0.49      5244\n",
      "weighted avg       0.92      0.96      0.94      5244\n",
      "\n",
      "Category: weather_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      3806\n",
      "           1       0.86      0.59      0.70      1438\n",
      "\n",
      "    accuracy                           0.86      5244\n",
      "   macro avg       0.86      0.78      0.80      5244\n",
      "weighted avg       0.86      0.86      0.85      5244\n",
      "\n",
      "Category: floods\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4833\n",
      "           1       0.91      0.41      0.57       411\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.93      0.71      0.77      5244\n",
      "weighted avg       0.95      0.95      0.94      5244\n",
      "\n",
      "Category: storm\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      4758\n",
      "           1       0.76      0.41      0.53       486\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.85      0.70      0.75      5244\n",
      "weighted avg       0.92      0.93      0.92      5244\n",
      "\n",
      "Category: fire\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5191\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "Category: earthquake\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4766\n",
      "           1       0.88      0.70      0.78       478\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.93      0.85      0.88      5244\n",
      "weighted avg       0.96      0.96      0.96      5244\n",
      "\n",
      "Category: cold\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5127\n",
      "           1       0.83      0.04      0.08       117\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.91      0.52      0.54      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "Category: other_weather\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4968\n",
      "           1       1.00      0.02      0.04       276\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.97      0.51      0.51      5244\n",
      "weighted avg       0.95      0.95      0.92      5244\n",
      "\n",
      "Category: direct_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      4223\n",
      "           1       0.84      0.32      0.46      1021\n",
      "\n",
      "    accuracy                           0.86      5244\n",
      "   macro avg       0.85      0.65      0.69      5244\n",
      "weighted avg       0.85      0.86      0.83      5244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/henriettewevell/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for cols in y_columns:\n",
    "    print(f\"Category: {cols}\\n\"\n",
    "          , classification_report(y_test[:,y_columns.get_loc(cols)], y_pred[:,y_columns.get_loc(cols)]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use grid search to find better parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__estimator__n_estimators': [50, 100, 200],\n",
    "    'clf__estimator__min_samples_split': [2, 3, 4],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3277122076.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[94], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    parameters =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "parameters = \n",
    "\n",
    "cv = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf_model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y must have at least two dimensions for multi-output regression but has only one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m multi_target_rf \u001b[39m=\u001b[39m MultiOutputClassifier(RandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[39m# fit the MultiOutputClassifier on the data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m multi_target_rf\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "File \u001b[0;32m~/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m    425\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \n\u001b[1;32m    427\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, Y, sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m [estimator\u001b[39m.\u001b[39mclasses_ \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_]\n\u001b[1;32m    452\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/src/udacity_disaster_response/venv/lib/python3.11/site-packages/sklearn/multioutput.py:204\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    201\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    205\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my must have at least two dimensions for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulti-output regression but has only one.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m has_fit_parameter(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator, \u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m ):\n\u001b[1;32m    212\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: y must have at least two dimensions for multi-output regression but has only one."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# generate some random data for demonstration purposes\n",
    "X, y = make_classification(n_samples=100, n_features=5, n_classes=3, n_informative=3, random_state=42)\n",
    "\n",
    "# create a MultiOutputClassifier with a RandomForestClassifier as the base estimator\n",
    "multi_target_rf = MultiOutputClassifier(RandomForestClassifier(random_state=42))\n",
    "\n",
    "# fit the MultiOutputClassifier on the data\n",
    "multi_target_rf.fit(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over each output category (i.e. each column in the target variable)\n",
    "for i in range(y.shape[1]):\n",
    "    target_col = y[:, i]\n",
    "    predicted_col = multi_target_rf.predict(X)[:, i]\n",
    "    print(f\"Classification report for output category {i}:\")\n",
    "    print(classification_report(target_col, predicted_col))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "adb49f2b326dd2745dc4f37ff4d1b42d5b7001b6ce5d8f6a25aafacce0b2f0cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
