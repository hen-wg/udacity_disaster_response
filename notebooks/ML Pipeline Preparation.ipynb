{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "For the machine learning portion, you will split the data into a training set and a test set. Then, you will create a machine learning pipeline that uses NLTK, as well as scikit-learn's Pipeline and GridSearchCV to output a final model that uses the message column to predict classifications for 36 categories (multi-output classification). Finally, you will export your model to a pickle file. After completing the notebook, you'll need to include your final machine learning code in train_classifier.py.\n",
    "\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# connect to the database\n",
    "conn = sqlite3.connect('../data/DisasterResponse.db')\n",
    "\n",
    "# run a query\n",
    "df = pd.read_sql('SELECT * FROM disaster_response_messages', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  water  food  shelter  \\\n",
       "0                  0         0         0            0      0     0        0   \n",
       "\n",
       "   clothing  money  missing_people  refugees  death  other_aid  \\\n",
       "0         0      0               0         0      0          0   \n",
       "\n",
       "   infrastructure_related  transport  buildings  electricity  tools  \\\n",
       "0                       0          0          0            0      0   \n",
       "\n",
       "   hospitals  shops  aid_centers  other_infrastructure  weather_related  \\\n",
       "0          0      0            0                     0                0   \n",
       "\n",
       "   floods  storm  fire  earthquake  cold  other_weather  direct_report  \n",
       "0       0      0     0           0     0              0              0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "#     df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "#     df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "#     X = df.text.values\n",
    "#     y = df.category.values\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[df.columns[4:]].values\n",
    "X = df['message'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[4:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download(['punkt', 'wordnet','stopwords'])\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/henriettewevell/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/henriettewevell/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# download necessary NLTK data\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all_urls(text: str) -> str:\n",
    "        url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "        detected_urls = re.findall(url_regex, text)\n",
    "        for url in detected_urls:\n",
    "             text = text.replace(url, \"urlplaceholder\")\n",
    "        return text\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    test = text.strip() # remove whitespaces\n",
    "    return test\n",
    "\n",
    "def tokenize(text : str) -> list:\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(text : list) -> list:\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    words = [w for w in text if w not in stop_words]\n",
    "    return words\n",
    "\n",
    "def lemmatize(text: list) -> list:\n",
    "    lemmatized_all = []\n",
    "    for word in text:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmatized_all.append(lemmatized)\n",
    "    return lemmatized_all\n",
    "\n",
    "\n",
    "def clean_and_tokenize(text: str) -> list:\n",
    "    text = replace_all_urls(text)\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize(tokens)\n",
    "    return tokens\n",
    "\n",
    "# def tokenize(text):\n",
    "#     detected_urls = re.findall(url_regex, text)\n",
    "#     for url in detected_urls:\n",
    "#         text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "#     tokens = word_tokenize(text)\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#     clean_tokens = []\n",
    "#     for tok in tokens:\n",
    "#         clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "#         clean_tokens.append(clean_tok)\n",
    "\n",
    "#     return clean_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['want',\n",
       " 'find',\n",
       " 'job',\n",
       " 'ngo',\n",
       " 'government',\n",
       " 'upload',\n",
       " 'resume',\n",
       " 'urlplaceholder']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_tokenize(\"If you want to find a Job at an NGO or the Government, upload your resume at http://www.jobpaw.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "# urls_df = df[df['message'].str.contains(url_regex)]['message'].head(1)\n",
    "# urls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilter the df messages column for when url is present\n",
    "# urls_df = df[df['message'].str.contains(url_regex)]['message'].head(5)\n",
    "# urls_df\n",
    "# number_regex = r'\\d+,\\d+'\n",
    "# # or number.number\n",
    "# number_regex2 = r'\\d+\\.\\d+'\n",
    "# # or number\n",
    "# number_regex3 = r'\\d+'\n",
    "\n",
    "# df[df['message'].str.contains(number_regex2)]['message'].sample(n=15)\n",
    "\n",
    "# filter the df messages column for number_regex or number_regex2 or number_regex3 is present\n",
    "# df[df['message'].str.contains(number_regex) | df['message'].str.contains(number_regex2) | df['message'].str.contains(number_regex3)]['message'].sample(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize(df.iloc[10]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_and_letters_regex = r'\\d+[a-zA-Z]+'\n",
    "# letters_and_number_regex = r'[a-zA-Z]+\\d+'\n",
    "# combined_regex = r'(\\d+[a-zA-Z]+)|([a-zA-Z]+\\d+)'\n",
    "# # df[df['message'].str.contains(number_and_letters_regex)]['message'].sample(n=15)\n",
    "\n",
    "# # get number_and_letters_regex from each message\n",
    "# df[df['message'].str.contains(letters_and_number_regex)]['message'].str.findall(letters_and_number_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['message'].str.contains(number_and_letters_regex)]['message'].str.findall(number_and_letters_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['message'].str.contains(combined_regex)]['message'].str.findall(combined_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df messages for when it contains any numbers\n",
    "# df[df['message'].str.contains('\\d')]['message'].sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "# lower case\n",
    "# lemmatize?\n",
    "# remove urls\n",
    "# remove punctuation\n",
    "# remove numbers?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train pipeline\n",
    "clf_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # load data and perform train text split\n",
    "#     X, y = load_data()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#     # instantiate transformers and classifiers\n",
    "#     vect = CountVectorizer(tokenizer=tokenize)\n",
    "#     tfidf = TfidfTransformer()\n",
    "#     clf = RandomForestClassifier()\n",
    "\n",
    "#     # fit and transform the training data\n",
    "#     X_train_counts = vect.fit_transform(X_train)\n",
    "#     X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "\n",
    "#     # train classifier\n",
    "#     clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#     # transform (no fitting) the test data\n",
    "#     X_test_counts = vect.transform(X_test)\n",
    "#     X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "#     # predict on test data\n",
    "#     y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "#     # display results\n",
    "#     display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# def display_results(y_test, y_pred):\n",
    "#     labels = np.unique(y_pred)\n",
    "#     confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "#     accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "#     print(\"Labels:\", labels)\n",
    "#     print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "#     print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "# display_results(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_columns = df[df.columns[4:]].columns\n",
    "y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.27      0.40      1266\n",
      "           1       0.80      0.97      0.88      3938\n",
      "           2       0.78      0.17      0.29        40\n",
      "\n",
      "    accuracy                           0.79      5244\n",
      "   macro avg       0.77      0.47      0.52      5244\n",
      "weighted avg       0.79      0.79      0.76      5244\n",
      "\n",
      "Category: request\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      4349\n",
      "           1       0.88      0.43      0.58       895\n",
      "\n",
      "    accuracy                           0.89      5244\n",
      "   macro avg       0.89      0.71      0.76      5244\n",
      "weighted avg       0.89      0.89      0.88      5244\n",
      "\n",
      "Category: offer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5218\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "Category: aid_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83      3113\n",
      "           1       0.80      0.61      0.69      2131\n",
      "\n",
      "    accuracy                           0.78      5244\n",
      "   macro avg       0.78      0.75      0.76      5244\n",
      "weighted avg       0.78      0.78      0.77      5244\n",
      "\n",
      "Category: medical_help\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4822\n",
      "           1       0.55      0.04      0.08       422\n",
      "\n",
      "    accuracy                           0.92      5244\n",
      "   macro avg       0.74      0.52      0.52      5244\n",
      "weighted avg       0.89      0.92      0.89      5244\n",
      "\n",
      "Category: medical_products\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4974\n",
      "           1       0.84      0.06      0.11       270\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.90      0.53      0.54      5244\n",
      "weighted avg       0.95      0.95      0.93      5244\n",
      "\n",
      "Category: search_and_rescue\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5117\n",
      "           1       0.75      0.07      0.13       127\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.86      0.54      0.56      5244\n",
      "weighted avg       0.97      0.98      0.97      5244\n",
      "\n",
      "Category: security\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5156\n",
      "           1       0.33      0.01      0.02        88\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.66      0.51      0.51      5244\n",
      "weighted avg       0.97      0.98      0.98      5244\n",
      "\n",
      "Category: military\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5089\n",
      "           1       0.50      0.05      0.08       155\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.74      0.52      0.53      5244\n",
      "weighted avg       0.96      0.97      0.96      5244\n",
      "\n",
      "Category: child_alone\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5244\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       1.00      1.00      1.00      5244\n",
      "weighted avg       1.00      1.00      1.00      5244\n",
      "\n",
      "Category: water\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4905\n",
      "           1       0.85      0.20      0.32       339\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.90      0.60      0.65      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "Category: food\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4649\n",
      "           1       0.92      0.40      0.56       595\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.92      0.70      0.76      5244\n",
      "weighted avg       0.93      0.93      0.91      5244\n",
      "\n",
      "Category: shelter\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4774\n",
      "           1       0.89      0.23      0.36       470\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.91      0.61      0.66      5244\n",
      "weighted avg       0.93      0.93      0.91      5244\n",
      "\n",
      "Category: clothing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5171\n",
      "           1       1.00      0.05      0.10        73\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.99      0.53      0.55      5244\n",
      "weighted avg       0.99      0.99      0.98      5244\n",
      "\n",
      "Category: money\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5140\n",
      "           1       0.78      0.07      0.12       104\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.88      0.53      0.56      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "Category: missing_people\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5184\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "Category: refugees\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      5073\n",
      "           1       0.67      0.01      0.02       171\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.82      0.51      0.50      5244\n",
      "weighted avg       0.96      0.97      0.95      5244\n",
      "\n",
      "Category: death\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5007\n",
      "           1       0.78      0.08      0.14       237\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.87      0.54      0.56      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "Category: other_aid\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4549\n",
      "           1       0.75      0.01      0.03       695\n",
      "\n",
      "    accuracy                           0.87      5244\n",
      "   macro avg       0.81      0.51      0.48      5244\n",
      "weighted avg       0.85      0.87      0.81      5244\n",
      "\n",
      "Category: infrastructure_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4916\n",
      "           1       0.00      0.00      0.00       328\n",
      "\n",
      "    accuracy                           0.94      5244\n",
      "   macro avg       0.47      0.50      0.48      5244\n",
      "weighted avg       0.88      0.94      0.91      5244\n",
      "\n",
      "Category: transport\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5004\n",
      "           1       0.73      0.09      0.16       240\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.85      0.55      0.57      5244\n",
      "weighted avg       0.95      0.96      0.94      5244\n",
      "\n",
      "Category: buildings\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      4977\n",
      "           1       0.89      0.06      0.11       267\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.92      0.53      0.54      5244\n",
      "weighted avg       0.95      0.95      0.93      5244\n",
      "\n",
      "Category: electricity\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5122\n",
      "           1       1.00      0.02      0.05       122\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.99      0.51      0.52      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "Category: tools\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5212\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      0.99      0.99      5244\n",
      "\n",
      "Category: hospitals\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5198\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.99      5244\n",
      "\n",
      "Category: shops\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5222\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           1.00      5244\n",
      "   macro avg       0.50      0.50      0.50      5244\n",
      "weighted avg       0.99      1.00      0.99      5244\n",
      "\n",
      "Category: aid_centers\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5177\n",
      "           1       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.97      0.99      0.98      5244\n",
      "\n",
      "Category: other_infrastructure\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5021\n",
      "           1       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           0.96      5244\n",
      "   macro avg       0.48      0.50      0.49      5244\n",
      "weighted avg       0.92      0.96      0.94      5244\n",
      "\n",
      "Category: weather_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      3806\n",
      "           1       0.86      0.59      0.70      1438\n",
      "\n",
      "    accuracy                           0.86      5244\n",
      "   macro avg       0.86      0.78      0.81      5244\n",
      "weighted avg       0.86      0.86      0.85      5244\n",
      "\n",
      "Category: floods\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4833\n",
      "           1       0.90      0.34      0.50       411\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.93      0.67      0.73      5244\n",
      "weighted avg       0.94      0.95      0.93      5244\n",
      "\n",
      "Category: storm\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      4758\n",
      "           1       0.76      0.41      0.53       486\n",
      "\n",
      "    accuracy                           0.93      5244\n",
      "   macro avg       0.85      0.70      0.75      5244\n",
      "weighted avg       0.93      0.93      0.92      5244\n",
      "\n",
      "Category: fire\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5191\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.99      5244\n",
      "   macro avg       0.49      0.50      0.50      5244\n",
      "weighted avg       0.98      0.99      0.98      5244\n",
      "\n",
      "Category: earthquake\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4766\n",
      "           1       0.89      0.73      0.80       478\n",
      "\n",
      "    accuracy                           0.97      5244\n",
      "   macro avg       0.93      0.86      0.89      5244\n",
      "weighted avg       0.97      0.97      0.97      5244\n",
      "\n",
      "Category: cold\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5127\n",
      "           1       0.90      0.08      0.14       117\n",
      "\n",
      "    accuracy                           0.98      5244\n",
      "   macro avg       0.94      0.54      0.57      5244\n",
      "weighted avg       0.98      0.98      0.97      5244\n",
      "\n",
      "Category: other_weather\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      4968\n",
      "           1       1.00      0.02      0.04       276\n",
      "\n",
      "    accuracy                           0.95      5244\n",
      "   macro avg       0.97      0.51      0.50      5244\n",
      "weighted avg       0.95      0.95      0.92      5244\n",
      "\n",
      "Category: direct_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      4223\n",
      "           1       0.84      0.32      0.46      1021\n",
      "\n",
      "    accuracy                           0.86      5244\n",
      "   macro avg       0.85      0.65      0.69      5244\n",
      "weighted avg       0.85      0.86      0.83      5244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for cols in y_columns:\n",
    "    print(f\"Category: {cols}\\n\"\n",
    "          , classification_report(y_test[:,y_columns.get_loc(cols)], y_pred[:,y_columns.get_loc(cols)]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use grid search to find better parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#     'tfidf__use_idf': (True, False),\n",
    "#     'clf__estimator__n_estimators': [50, 100, 200],\n",
    "#     'clf__estimator__min_samples_split': [2, 3, 4],\n",
    "#     # 'clf__estimator__max_depth': [None, 5, 10],              \n",
    "# }\n",
    "\n",
    "parameters = {\n",
    "    # 'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    'clf__estimator__n_estimators': [50, 100],\n",
    "    'clf__estimator__min_samples_split': [2, 3],\n",
    "    # 'clf__estimator__max_depth': [None, 5, 10],              \n",
    "}\n",
    "\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, n_jobs= -1 , verbose=3, cv = 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50;, score=0.222 total time= 1.6min\n",
      "[CV 2/2] END clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50;, score=0.225 total time= 1.6min\n",
      "[CV 1/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50;, score=0.225 total time= 1.7min\n",
      "[CV 2/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50;, score=0.228 total time= 1.8min\n",
      "[CV 1/2] END clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100;, score=0.229 total time= 2.8min\n",
      "[CV 2/2] END clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100;, score=0.232 total time= 2.8min\n",
      "[CV 1/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100;, score=0.229 total time= 3.0min\n",
      "[CV 2/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100;, score=0.236 total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(tokenizer=&lt;function tokenize at 0x7fac29b4e710&gt;)),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__estimator__min_samples_split&#x27;: [2, 3],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(tokenizer=&lt;function tokenize at 0x7fac29b4e710&gt;)),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__estimator__min_samples_split&#x27;: [2, 3],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x7fac29b4e710&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x7fac29b4e710&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x7fac29b4e710>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__estimator__min_samples_split': [2, 3],\n",
       "                         'clf__estimator__n_estimators': [50, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit new model\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'clf__estimator__min_samples_split': 2, 'clf__estimator__n_estimators': 100}\n",
      "Best mean test score: 0.23250047682624453\n"
     ]
    }
   ],
   "source": [
    "# print the best hyperparameters and the corresponding mean test score\n",
    "print(f\"Best hyperparameters: {cv.best_params_}\")\n",
    "print(f\"Best mean test score: {cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator__min_samples_split</th>\n",
       "      <th>param_clf__estimator__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.216964</td>\n",
       "      <td>2.371306</td>\n",
       "      <td>9.290158</td>\n",
       "      <td>0.192229</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.224967</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.226683</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173.919629</td>\n",
       "      <td>5.711196</td>\n",
       "      <td>13.151606</td>\n",
       "      <td>0.154142</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 2, 'clf_...</td>\n",
       "      <td>0.228972</td>\n",
       "      <td>0.236029</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.702118</td>\n",
       "      <td>1.483077</td>\n",
       "      <td>9.629261</td>\n",
       "      <td>0.096257</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 3, 'clf_...</td>\n",
       "      <td>0.221533</td>\n",
       "      <td>0.224776</td>\n",
       "      <td>0.223155</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.444923</td>\n",
       "      <td>1.335241</td>\n",
       "      <td>14.518931</td>\n",
       "      <td>0.189263</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'clf__estimator__min_samples_split': 3, 'clf_...</td>\n",
       "      <td>0.229449</td>\n",
       "      <td>0.232024</td>\n",
       "      <td>0.230736</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      96.216964      2.371306         9.290158        0.192229   \n",
       "1     173.919629      5.711196        13.151606        0.154142   \n",
       "2      86.702118      1.483077         9.629261        0.096257   \n",
       "3     154.444923      1.335241        14.518931        0.189263   \n",
       "\n",
       "  param_clf__estimator__min_samples_split param_clf__estimator__n_estimators  \\\n",
       "0                                       2                                 50   \n",
       "1                                       2                                100   \n",
       "2                                       3                                 50   \n",
       "3                                       3                                100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__estimator__min_samples_split': 2, 'clf_...           0.224967   \n",
       "1  {'clf__estimator__min_samples_split': 2, 'clf_...           0.228972   \n",
       "2  {'clf__estimator__min_samples_split': 3, 'clf_...           0.221533   \n",
       "3  {'clf__estimator__min_samples_split': 3, 'clf_...           0.229449   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.228400         0.226683        0.001717                3  \n",
       "1           0.236029         0.232500        0.003529                1  \n",
       "2           0.224776         0.223155        0.001621                4  \n",
       "3           0.232024         0.230736        0.001287                2  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_results = pd.DataFrame(cv.cv_results_)\n",
    "improved_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_y_pred = cv.predict(X_test)\n",
    "improved_y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf_model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "adb49f2b326dd2745dc4f37ff4d1b42d5b7001b6ce5d8f6a25aafacce0b2f0cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
