{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "For the machine learning portion, you will split the data into a training set and a test set. Then, you will create a machine learning pipeline that uses NLTK, as well as scikit-learn's Pipeline and GridSearchCV to output a final model that uses the message column to predict classifications for 36 categories (multi-output classification). Finally, you will export your model to a pickle file. After completing the notebook, you'll need to include your final machine learning code in train_classifier.py.\n",
    "\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# connect to the database\n",
    "conn = sqlite3.connect('../data/DisasterResponse.db')\n",
    "\n",
    "# run a query\n",
    "df = pd.read_sql('SELECT * FROM disaster_response_messages', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that could pass over Haiti</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. Il pourrait traverser Haiti demain. Des averses de pluie isolee sont encore prevues sur notre region ce soi</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                             message  \\\n",
       "0   2  Weather update - a cold front from Cuba that could pass over Haiti   \n",
       "\n",
       "                                                                                                                                                    original  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. Il pourrait traverser Haiti demain. Des averses de pluie isolee sont encore prevues sur notre region ce soi   \n",
       "\n",
       "    genre  related  request  offer  aid_related  medical_help  \\\n",
       "0  direct        1        0      0            0             0   \n",
       "\n",
       "   medical_products  ...  aid_centers  other_infrastructure  weather_related  \\\n",
       "0                 0  ...            0                     0                0   \n",
       "\n",
       "   floods  storm  fire  earthquake  cold  other_weather  direct_report  \n",
       "0       0      0     0           0     0              0              0  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "#     df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "#     df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "#     X = df.text.values\n",
    "#     y = df.category.values\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[df.columns[4:]].values\n",
    "X = df['message'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/henriettewevell/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/henriettewevell/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# download necessary NLTK data\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all_urls(text):\n",
    "        url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "        detected_urls = re.findall(url_regex, text)\n",
    "        for url in detected_urls:\n",
    "             text = text.replace(url, \"urlplaceholder\")\n",
    "        return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    test = text.strip() # remove whitespaces\n",
    "    return test\n",
    "\n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    words = [w for w in text if w not in stop_words]\n",
    "    return words\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatized_all = []\n",
    "    for word in text:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmatized_all.append(lemmatized)\n",
    "    return lemmatized_all\n",
    "\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    text = replace_all_urls(text)\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize(tokens)\n",
    "    return tokens\n",
    "\n",
    "# def tokenize(text):\n",
    "#     detected_urls = re.findall(url_regex, text)\n",
    "#     for url in detected_urls:\n",
    "#         text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "#     tokens = word_tokenize(text)\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#     clean_tokens = []\n",
    "#     for tok in tokens:\n",
    "#         clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "#         clean_tokens.append(clean_tok)\n",
    "\n",
    "#     return clean_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['want',\n",
       " 'find',\n",
       " 'job',\n",
       " 'ngo',\n",
       " 'government',\n",
       " 'upload',\n",
       " 'resume',\n",
       " 'urlplaceholder']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_tokenize(\"If you want to find a Job at an NGO or the Government, upload your resume at http://www.jobpaw.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5026    If you want to find a Job at an NGO or the Government, upload your resume at http://www.jobpaw.com/ \n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "urls_df = df[df['message'].str.contains(url_regex)]['message'].head(1)\n",
    "urls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17605                                                                                                                                                                                                                                                                                                                                                                            About 12.0% were afflicted with dyspepsia, an indigestion characterised by abdominal discomfort, eructation, heartburn, nausea or vomiting.\n",
       "15884    Three firefighting helicopters Ka-32 and one Mi-26 are ready to fight fires in Shaturskiy, Yegoryevskiy and Orekhovo-Zuevo Regions. Australia's representative welcomed that IAEA's Director General had quickly set up a task force to enhance response capacities to outbreaks of zoonotic diseases, including the Ebola virus. Meanwhile, in Jakarta, incessant rain and high tides inundated several subdistricts in North and West Jakarta, the Jakarta Regional Disaster Mitigation Agency (BPBD) spokesma...\n",
       "10330                                                                                                                                                                                                                                                                                                                                                                                       RT NewsEarthquakes Orange earthquake alert Haiti M=5.5 potentially affecting 4.8 million people. http url4.eu 17F0Y via florisvc\n",
       "17063                                                                                                                                                                                                                                                                                                                                                             By 2070, the average temperature for the central provinces will increase by 2.5=B0C, average rainfall will be up 19 percent and sea levels will rise 45cm.\n",
       "13627                                                                                                                                                                                                                                                                                                                                                                                                                                  A 6.8-magnitude earthquake jolted the county on Sunday night, affecting 7,645 people.\n",
       "9929                                                                                                                                                                                                                                                                                                                                                                                RT OrphanProject Most of you have probably heard this but Haiti was hit by a 7.3 Magnitude earthquake at approx. 4 30pm today. .. htt ..\n",
       "14388                                                                                                                                                            Experts from Indonesia's state-run Directorate-General of Vulcanology said the increased activity of Mount Talang was triggered by a series of earthquakes that have jolted Sumatra in recent months, including a 6.7-magnitude tremblor on Sunday that had its epicentre in the Indian Ocean, close to the Mentawai islands off the coast of West Sumatra.\n",
       "20948                                                                                              The cumulative effect of flooding in both 2008 and 2009, in combination with the low levels of resilience, increased the levels of vulnerability especially for the large proportion of the population affected by human immuno-deficiency virus (HIV) and Acquired Immuno-deficiency Syndrome (AIDS) (Namibia has one of the highest prevalence rates in the world, estimated in 2008 at 17.8% of the adult population).\n",
       "10327                                                                                                                                                                                                                                                                                                                                                                                  RT thegoodhuman RT jerryjamesstone BREAKING A 7.0 earthquake has hit the country of Haiti & a hospital has collapsed and a tsunami ..\n",
       "10284                                                                                                                                                                                                                                                                                                                                                                                       Thousands Feared Dead in Haiti Earthquake Magnitude 7.0 only 10 miles from Port au Prince collapsed building. http bit.ly 5fDmEk\n",
       "16959                                                                                                                                                                                                                                                                                                                                          Since we were founded in 1962, we have provided about 2.25 billion euros worth of funding for around 6,600 projects in 70 countries - for a world without hunger and poverty.\n",
       "18012                                                                                                                                                                                                                                                            Economic losses in the three provinces are estimated at $15.2 billion, but without the massive flood-fighting operation mounted by the central government, the provinces, local governments, and the armed services, the damage would have been much worse.\n",
       "15474                                                                                                                                                                                                                                                                                         Then there was a powerful outburst, which resulted in a flash flood in the Seti river that entered human settlements and created havoc, he told AFP, adding some houses were covered with mud up to 12 feet (3.5 metres) deep.\n",
       "17242                                                                                                                                                                                                                                                                                Approximately 722,500 homes have been destroyed, 1.4m acres (557,000 hectares) of crop lands have been flooded and more than 10,000 cows have died, according to figures released by Pakistan's National Disaster Management Authority.\n",
       "16086                                                                                                                                                                          Distributing relief materials in the flood-hit areas in Jamalpur yesterday, he said that the government has undertaken a plan to construct a 4.5-km embankment at Dewanganj hard point and urged the farmers to plant Aman after recession of floodwaters, as seedbeds are being prepared under the supervision of Army, newspapers reported.\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dilter the df messages column for when url is present\n",
    "# urls_df = df[df['message'].str.contains(url_regex)]['message'].head(5)\n",
    "# urls_df\n",
    "number_regex = r'\\d+,\\d+'\n",
    "# or number.number\n",
    "number_regex2 = r'\\d+\\.\\d+'\n",
    "# or number\n",
    "number_regex3 = r'\\d+'\n",
    "\n",
    "df[df['message'].str.contains(number_regex2)]['message'].sample(n=15)\n",
    "\n",
    "# filter the df messages column for number_regex or number_regex2 or number_regex3 is present\n",
    "# df[df['message'].str.contains(number_regex) | df['message'].str.contains(number_regex2) | df['message'].str.contains(number_regex3)]['message'].sample(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " \"'s\",\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'eat',\n",
       " 'and',\n",
       " 'water',\n",
       " ',',\n",
       " 'we',\n",
       " 'starving',\n",
       " 'and',\n",
       " 'thirsty',\n",
       " '.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df.iloc[10]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183              [A1]\n",
       "572              [i1]\n",
       "2670            [x28]\n",
       "2807         [someo9]\n",
       "3778    [Lillavois47]\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_and_letters_regex = r'\\d+[a-zA-Z]+'\n",
    "letters_and_number_regex = r'[a-zA-Z]+\\d+'\n",
    "combined_regex = r'(\\d+[a-zA-Z]+)|([a-zA-Z]+\\d+)'\n",
    "# df[df['message'].str.contains(number_and_letters_regex)]['message'].sample(n=15)\n",
    "\n",
    "# get number_and_letters_regex from each message\n",
    "df[df['message'].str.contains(letters_and_number_regex)]['message'].str.findall(letters_and_number_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72     [12th]\n",
       "153     [40B]\n",
       "166     [3rd]\n",
       "200    [2hrs]\n",
       "272    [12th]\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['message'].str.contains(number_and_letters_regex)]['message'].str.findall(number_and_letters_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_416/1235753974.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[df['message'].str.contains(combined_regex)]['message'].str.findall(combined_regex).head()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72     [(12th, )]\n",
       "153     [(40B, )]\n",
       "166     [(3rd, )]\n",
       "183      [(, A1)]\n",
       "200    [(2hrs, )]\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['message'].str.contains(combined_regex)]['message'].str.findall(combined_regex).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23464                                                                                                                                                                                                                                                                                                                                                                                                        In December he won 77 percent of the votes in the presidential race.\n",
       "16193                                                                                                                                                                                                                                                       The delay in the advance of monsoon over the northeast and its stagnation along the west coast after 8 June had been primarily due to the interference of high latitude circulation features with the monsoonal flow.\n",
       "24877                                                                                                                                                                                                                                                                                            Jonathan's Peoples Democratic Party (PDP) has been in power since Nigeria returned to civilian rule in 1999 but is being pushed to the wire by main opposition candidate Buhari.\n",
       "4021                                                                                                                                                                                                                                                                                      I'm thankful for the international corps (CRS) for food it gave this morning in Delmas 62 even if this is rice to give us time for the rest of the stuff. We need a tent for the rain. \n",
       "18801    As a result of today's decisions, the World Bank Group will mobilize US$600 million in development financing for the third phase of the Promoting Basic Services (PBS III) program, which serves approximately 84 million people across Ethiopia, and is co-financed by the Government of Ethiopia, and other development partners such as the European Union, the UK Department for International Development, the African Development Bank, Italy, Austria and others.\n",
       "18743                                                                                                                                                                                                                     As the 18th Air Force's hub for global operations, members of the 618th TACC plan, schedule and direct a fleet of nearly 1,300 mobility aircraft in support of strategic airlift, air refueling and aeromedical evacuation operations around the world.\n",
       "4779                                                                                                                                                                                                                                                                                                                                                                                                I would like to have information regarding the number 4636. How do I use it? \n",
       "21884                      In a November overview, the UN Children's Fund (UNICEF) [ http://reliefweb.int/sites/reliefweb.int/files/resources/Full%20Report_318.pdf ] expressed concern over the plight of people who return home to \"dismal conditions\", while the Sindh Provincial Disaster Management Authority stated that as of 5 November, [ http://pdma.pk/siterip/0511SitRep.pdf ] there were 9,178,811 flood-affected people across Sindh, 1,237,432 of them in Sanghar.\n",
       "17688                         YANGON, 23 May 2011 (IRIN) - The recent 6.8 quake that shook Myanmar's northeastern Shan State, killing 74 and affecting 18,000 [[http://www.themimu.info/Earthquake/Shan_Earthquake/Reports/110330_OCHA_Sit_Rep_5_Myanmar_Earthquake.pdf](http://www.themimu.info/Earthquake/Shan_Earthquake/Reports/110330_OCHA_Sit_Rep_5_Myanmar_Earthquake.pdf)], serves as a stark warning for this largely unprepared, earthquake-prone country, say experts.\n",
       "24089                                                                                                                                                                                                                                                                                                  Since the beginning of the year 11,000 people have contracted cholera in Chad, and 340 have died, according to the UN Office for the Coordination of Humanitarian Affairs.\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter df messages for when it contains any numbers\n",
    "df[df['message'].str.contains('\\d')]['message'].sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "# lower case\n",
    "# lemmatize?\n",
    "# remove urls\n",
    "# remove punctuation\n",
    "# remove numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load data and perform train text split\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # instantiate transformers and classifiers\n",
    "    vect = CountVectorizer(tokenizer=tokenize)\n",
    "    tfidf = TfidfTransformer()\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    # fit and transform the training data\n",
    "    X_train_counts = vect.fit_transform(X_train)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "\n",
    "    # train classifier\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # transform (no fitting) the test data\n",
    "    X_test_counts = vect.transform(X_test)\n",
    "    X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "    # predict on test data\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    # display results\n",
    "    display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henriettewevell/wsl-repos/udacity_disaster_response/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf =   pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred\n",
    "# display results\n",
    "# display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3277122076.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    parameters =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "parameters = \n",
    "\n",
    "cv = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "adb49f2b326dd2745dc4f37ff4d1b42d5b7001b6ce5d8f6a25aafacce0b2f0cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
